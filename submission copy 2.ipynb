{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Важная настройка для корректной настройки pipeline!\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler, OrdinalEncoder, QuantileTransformer, PowerTransformer, MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import make_column_selector, TransformedTargetRegressor\n",
    "\n",
    "# for model learning\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "#models\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostRegressor\n",
    "# import xgboost as xgb\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "# Игнорировать все предупреждения\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "\n",
    "# tunning hyperparamters model\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice        1.000000\n",
      "OverallQual      0.790982\n",
      "GrLivArea        0.708624\n",
      "GarageCars       0.640409\n",
      "GarageArea       0.623431\n",
      "TotalBsmtSF      0.613581\n",
      "1stFlrSF         0.605852\n",
      "FullBath         0.560664\n",
      "TotRmsAbvGrd     0.533723\n",
      "YearBuilt        0.522897\n",
      "YearRemodAdd     0.507101\n",
      "GarageYrBlt      0.486362\n",
      "MasVnrArea       0.477493\n",
      "Fireplaces       0.466929\n",
      "BsmtFinSF1       0.386420\n",
      "LotFrontage      0.351799\n",
      "WoodDeckSF       0.324413\n",
      "2ndFlrSF         0.319334\n",
      "OpenPorchSF      0.315856\n",
      "HalfBath         0.284108\n",
      "LotArea          0.263843\n",
      "BsmtFullBath     0.227122\n",
      "BsmtUnfSF        0.214479\n",
      "BedroomAbvGr     0.168213\n",
      "ScreenPorch      0.111447\n",
      "PoolArea         0.092404\n",
      "MoSold           0.046432\n",
      "3SsnPorch        0.044584\n",
      "BsmtFinSF2      -0.011378\n",
      "BsmtHalfBath    -0.016844\n",
      "MiscVal         -0.021190\n",
      "Id              -0.021917\n",
      "LowQualFinSF    -0.025606\n",
      "YrSold          -0.028923\n",
      "OverallCond     -0.077856\n",
      "MSSubClass      -0.084284\n",
      "EnclosedPorch   -0.128578\n",
      "KitchenAbvGr    -0.135907\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = data_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Вычисление корреляций с целевой переменной\n",
    "correlations = data_train[numerical_columns].apply(lambda x: x.corr(data_train['SalePrice']), axis=0).sort_values(ascending=False)\n",
    "\n",
    "# Вывод списка корреляций\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   700,   350,   500,   400,   480,   450, 15500,  1200,\n",
       "         800,  2000,   600,  3500,  1300,    54,   620,   560,  1400,\n",
       "        8300,  1150,  2500])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['MiscVal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PoolArea', 'MoSold', '3SsnPorch', 'BsmtFinSF2', 'BsmtHalfBath', 'MiscVal', 'Id', 'LowQualFinSF', 'YrSold', 'OverallCond', 'MSSubClass']\n"
     ]
    }
   ],
   "source": [
    "filtered_correlations = correlations[(correlations >= -0.1) & (correlations <= 0.1)]\n",
    "\n",
    "# Вывод списка имен столбцов\n",
    "selected_columns = filtered_correlations.index.tolist()\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_train.drop('SalePrice', axis=1), data_train['SalePrice']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = data_train.select_dtypes(include='object').columns.to_list()\n",
    "num_cols = data_train.select_dtypes(include=['float64', 'int64']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = ['Id','Alley','MasVnrType','FireplaceQu','PoolQC','Fence','MiscFeature','LandSlope','GarageQual','GarageCond','MiscVal','Utilities','YrSold', 'MSSubClass','OverallCond', 'LowQualFinSF', 'MiscVal', 'BsmtHalfBath', '3SsnPorch', 'MoSold', 'PoolArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imputer = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('drop_features', 'drop', drop_features),\n",
    "        ('num_imputer', SimpleImputer(strategy='mean'), make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent'), make_column_selector(dtype_include='object'))\n",
    "    ],\n",
    "    verbose_feature_names_out = False,\n",
    "    remainder = 'passthrough'\n",
    ") \n",
    "\n",
    "filled_data = my_imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN_count</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleType</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               NaN_count data_type\n",
       "Id                     0   float64\n",
       "MSSubClass             0   float64\n",
       "LotFrontage            0   float64\n",
       "LotArea                0   float64\n",
       "OverallQual            0   float64\n",
       "...                  ...       ...\n",
       "PoolQC                 0    object\n",
       "Fence                  0    object\n",
       "MiscFeature            0    object\n",
       "SaleType               0    object\n",
       "SaleCondition          0    object\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'NaN_count': filled_data.isna().sum(), 'data_type':filled_data.dtypes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "MSSubClass       0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "OverallQual      0\n",
       "                ..\n",
       "PoolQC           0\n",
       "Fence            0\n",
       "MiscFeature      0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_imputer.transform(X_train).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_and_encoder = ColumnTransformer(\n",
    "    [\n",
    "        ('target_encoding', TargetEncoder(), make_column_selector(dtype_include='object')),\n",
    "        ('scaling_num_columns', StandardScaler(), make_column_selector(dtype_include=['float64', 'int64']))\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_for_obj = ColumnTransformer(\n",
    "    [\n",
    "        ('scaling2', StandardScaler(), make_column_selector(dtype_include=['float64', 'int64']))\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        ('imputer', my_imputer),\n",
    "        ('scaler_and_encoder', scaler_and_encoder),\n",
    "        ('scaling2', scaler_for_obj)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>-0.770813</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>-0.365252</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>-0.723815</td>\n",
       "      <td>0.598954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995829</td>\n",
       "      <td>-0.757412</td>\n",
       "      <td>1.890607</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>0.251991</td>\n",
       "      <td>-0.617357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>-2.321569</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>-0.770813</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>-0.365252</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>0.469327</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256081</td>\n",
       "      <td>0.336709</td>\n",
       "      <td>-0.712142</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>-0.484876</td>\n",
       "      <td>0.888463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>-5.654002</td>\n",
       "      <td>-0.770813</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>-0.365252</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>-1.076576</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.109636</td>\n",
       "      <td>-0.757412</td>\n",
       "      <td>-0.712142</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>0.251991</td>\n",
       "      <td>0.135553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>1.958855</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>3.523470</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>0.469327</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>1.299288</td>\n",
       "      <td>0.789988</td>\n",
       "      <td>1.611741</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>0.620425</td>\n",
       "      <td>-1.370266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>-1.045823</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>-0.770813</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>-0.365252</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>-1.173379</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787182</td>\n",
       "      <td>-0.757412</td>\n",
       "      <td>-0.712142</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>1.357292</td>\n",
       "      <td>-1.370266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>-0.770813</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.441674</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>-0.921239</td>\n",
       "      <td>-3.131216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654407</td>\n",
       "      <td>-0.757412</td>\n",
       "      <td>-0.712142</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>-0.484876</td>\n",
       "      <td>1.641373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>1.226862</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>-0.365252</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>0.265383</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213403</td>\n",
       "      <td>0.743097</td>\n",
       "      <td>-0.712142</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>-1.590177</td>\n",
       "      <td>-1.370266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>1.226862</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>-0.365252</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>0.265383</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350920</td>\n",
       "      <td>0.180406</td>\n",
       "      <td>-0.309336</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>0.251991</td>\n",
       "      <td>0.888463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>-0.770813</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.441674</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>-0.723815</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.882022</td>\n",
       "      <td>-0.483882</td>\n",
       "      <td>-0.712142</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>2.094159</td>\n",
       "      <td>-0.617357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>1.226862</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>3.523470</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>0.381854</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>0.196036</td>\n",
       "      <td>-0.247365</td>\n",
       "      <td>-0.360412</td>\n",
       "      <td>-0.109151</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>-0.076003</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>-0.484876</td>\n",
       "      <td>0.135553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSZoning    Street     Alley  LotShape  LandContour  Utilities  \\\n",
       "397   0.423421  0.062684  0.176866 -0.770813     0.056616   0.031296   \n",
       "593  -2.321569  0.062684  0.176866 -0.770813     0.056616   0.031296   \n",
       "361   0.423421  0.062684 -5.654002 -0.770813     0.056616   0.031296   \n",
       "1318  0.423421  0.062684  0.176866  1.958855     0.056616   0.031296   \n",
       "916  -1.045823  0.062684  0.176866 -0.770813     0.056616   0.031296   \n",
       "...        ...       ...       ...       ...          ...        ...   \n",
       "228   0.423421  0.062684  0.176866 -0.770813     0.056616   0.031296   \n",
       "255   0.423421  0.062684  0.176866  1.226862     0.056616   0.031296   \n",
       "356   0.423421  0.062684  0.176866  1.226862     0.056616   0.031296   \n",
       "574   0.423421  0.062684  0.176866 -0.770813     0.056616   0.031296   \n",
       "326   0.423421  0.062684  0.176866  1.226862     0.056616   0.031296   \n",
       "\n",
       "      LotConfig  LandSlope  Neighborhood  Condition1  ...  GarageArea  \\\n",
       "397   -0.365252  -0.172473     -0.723815    0.598954  ...   -0.995829   \n",
       "593   -0.365252  -0.172473      0.469327    0.322606  ...   -0.256081   \n",
       "361   -0.365252  -0.172473     -1.076576    0.322606  ...   -1.109636   \n",
       "1318   3.523470  -0.172473      0.469327    0.322606  ...    1.299288   \n",
       "916   -0.365252  -0.172473     -1.173379    0.322606  ...   -0.787182   \n",
       "...         ...        ...           ...         ...  ...         ...   \n",
       "228    0.441674  -0.172473     -0.921239   -3.131216  ...   -0.654407   \n",
       "255   -0.365252  -0.172473      0.265383    0.322606  ...   -0.213403   \n",
       "356   -0.365252  -0.172473      0.265383    0.322606  ...   -0.350920   \n",
       "574    0.441674  -0.172473     -0.723815    0.322606  ...   -0.882022   \n",
       "326    3.523470  -0.172473      0.381854    0.322606  ...   -0.004756   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "397    -0.757412     1.890607      -0.360412  -0.109151    -0.269692   \n",
       "593     0.336709    -0.712142      -0.360412  -0.109151    -0.269692   \n",
       "361    -0.757412    -0.712142      -0.360412  -0.109151    -0.269692   \n",
       "1318    0.789988     1.611741      -0.360412  -0.109151    -0.269692   \n",
       "916    -0.757412    -0.712142      -0.360412  -0.109151    -0.269692   \n",
       "...          ...          ...            ...        ...          ...   \n",
       "228    -0.757412    -0.712142      -0.360412  -0.109151    -0.269692   \n",
       "255     0.743097    -0.712142      -0.360412  -0.109151    -0.269692   \n",
       "356     0.180406    -0.309336      -0.360412  -0.109151    -0.269692   \n",
       "574    -0.483882    -0.712142      -0.360412  -0.109151    -0.269692   \n",
       "326     0.196036    -0.247365      -0.360412  -0.109151    -0.269692   \n",
       "\n",
       "      PoolArea   MiscVal    MoSold    YrSold  \n",
       "397  -0.076003 -0.093955  0.251991 -0.617357  \n",
       "593  -0.076003 -0.093955 -0.484876  0.888463  \n",
       "361  -0.076003 -0.093955  0.251991  0.135553  \n",
       "1318 -0.076003 -0.093955  0.620425 -1.370266  \n",
       "916  -0.076003 -0.093955  1.357292 -1.370266  \n",
       "...        ...       ...       ...       ...  \n",
       "228  -0.076003 -0.093955 -0.484876  1.641373  \n",
       "255  -0.076003 -0.093955 -1.590177 -1.370266  \n",
       "356  -0.076003 -0.093955  0.251991  0.888463  \n",
       "574  -0.076003 -0.093955  2.094159 -0.617357  \n",
       "326  -0.076003 -0.093955 -0.484876  0.135553  \n",
       "\n",
       "[1022 rows x 80 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = preprocessor.fit_transform(X_train, y_train)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.115677\n",
      "0:\tlearn: 73223.8093097\ttotal: 4.3ms\tremaining: 1.29s\n",
      "1:\tlearn: 67614.9809608\ttotal: 10ms\tremaining: 1.49s\n",
      "2:\tlearn: 62926.4171711\ttotal: 16.5ms\tremaining: 1.64s\n",
      "3:\tlearn: 58991.5537579\ttotal: 24ms\tremaining: 1.77s\n",
      "4:\tlearn: 55054.2695503\ttotal: 32.2ms\tremaining: 1.9s\n",
      "5:\tlearn: 51849.9339992\ttotal: 38.9ms\tremaining: 1.91s\n",
      "6:\tlearn: 48971.5061083\ttotal: 45.4ms\tremaining: 1.9s\n",
      "7:\tlearn: 46194.4401313\ttotal: 50.9ms\tremaining: 1.86s\n",
      "8:\tlearn: 44031.7946279\ttotal: 57.6ms\tremaining: 1.86s\n",
      "9:\tlearn: 41901.2586725\ttotal: 62.3ms\tremaining: 1.8s\n",
      "10:\tlearn: 40180.0679383\ttotal: 66.6ms\tremaining: 1.75s\n",
      "11:\tlearn: 38672.8799523\ttotal: 76ms\tremaining: 1.82s\n",
      "12:\tlearn: 36867.6167753\ttotal: 80.1ms\tremaining: 1.77s\n",
      "13:\tlearn: 35419.5207987\ttotal: 86ms\tremaining: 1.76s\n",
      "14:\tlearn: 34063.9452960\ttotal: 91.4ms\tremaining: 1.74s\n",
      "15:\tlearn: 32768.5408398\ttotal: 95.6ms\tremaining: 1.7s\n",
      "16:\tlearn: 31577.8939693\ttotal: 104ms\tremaining: 1.73s\n",
      "17:\tlearn: 30638.6506914\ttotal: 111ms\tremaining: 1.74s\n",
      "18:\tlearn: 29701.1246958\ttotal: 121ms\tremaining: 1.79s\n",
      "19:\tlearn: 28743.2420807\ttotal: 126ms\tremaining: 1.76s\n",
      "20:\tlearn: 28065.0653950\ttotal: 131ms\tremaining: 1.74s\n",
      "21:\tlearn: 27357.0056209\ttotal: 140ms\tremaining: 1.76s\n",
      "22:\tlearn: 26734.1590202\ttotal: 145ms\tremaining: 1.74s\n",
      "23:\tlearn: 26146.6598110\ttotal: 153ms\tremaining: 1.75s\n",
      "24:\tlearn: 25568.2844207\ttotal: 158ms\tremaining: 1.73s\n",
      "25:\tlearn: 25016.2069044\ttotal: 162ms\tremaining: 1.71s\n",
      "26:\tlearn: 24524.9013018\ttotal: 176ms\tremaining: 1.78s\n",
      "27:\tlearn: 24040.0568532\ttotal: 184ms\tremaining: 1.79s\n",
      "28:\tlearn: 23596.0314855\ttotal: 190ms\tremaining: 1.77s\n",
      "29:\tlearn: 23191.1987033\ttotal: 196ms\tremaining: 1.76s\n",
      "30:\tlearn: 22846.1046916\ttotal: 204ms\tremaining: 1.77s\n",
      "31:\tlearn: 22558.3907579\ttotal: 221ms\tremaining: 1.85s\n",
      "32:\tlearn: 22270.2131676\ttotal: 227ms\tremaining: 1.83s\n",
      "33:\tlearn: 21976.7729671\ttotal: 239ms\tremaining: 1.87s\n",
      "34:\tlearn: 21782.7215824\ttotal: 254ms\tremaining: 1.92s\n",
      "35:\tlearn: 21468.7048901\ttotal: 265ms\tremaining: 1.94s\n",
      "36:\tlearn: 21287.8168270\ttotal: 272ms\tremaining: 1.93s\n",
      "37:\tlearn: 20995.0309907\ttotal: 284ms\tremaining: 1.96s\n",
      "38:\tlearn: 20757.2039744\ttotal: 291ms\tremaining: 1.95s\n",
      "39:\tlearn: 20537.1714981\ttotal: 302ms\tremaining: 1.97s\n",
      "40:\tlearn: 20316.8187246\ttotal: 312ms\tremaining: 1.97s\n",
      "41:\tlearn: 20111.7428933\ttotal: 321ms\tremaining: 1.97s\n",
      "42:\tlearn: 20014.0045868\ttotal: 329ms\tremaining: 1.97s\n",
      "43:\tlearn: 19813.5229827\ttotal: 338ms\tremaining: 1.97s\n",
      "44:\tlearn: 19701.4022556\ttotal: 346ms\tremaining: 1.96s\n",
      "45:\tlearn: 19642.0398263\ttotal: 350ms\tremaining: 1.93s\n",
      "46:\tlearn: 19468.3315171\ttotal: 357ms\tremaining: 1.92s\n",
      "47:\tlearn: 19317.2908299\ttotal: 365ms\tremaining: 1.92s\n",
      "48:\tlearn: 19164.1529571\ttotal: 369ms\tremaining: 1.89s\n",
      "49:\tlearn: 19014.0760225\ttotal: 377ms\tremaining: 1.88s\n",
      "50:\tlearn: 18878.3113751\ttotal: 384ms\tremaining: 1.88s\n",
      "51:\tlearn: 18756.0293452\ttotal: 394ms\tremaining: 1.88s\n",
      "52:\tlearn: 18669.1217582\ttotal: 417ms\tremaining: 1.94s\n",
      "53:\tlearn: 18539.2752654\ttotal: 426ms\tremaining: 1.94s\n",
      "54:\tlearn: 18423.9083770\ttotal: 443ms\tremaining: 1.98s\n",
      "55:\tlearn: 18332.1425074\ttotal: 448ms\tremaining: 1.95s\n",
      "56:\tlearn: 18261.3113300\ttotal: 464ms\tremaining: 1.98s\n",
      "57:\tlearn: 18146.6153428\ttotal: 478ms\tremaining: 1.99s\n",
      "58:\tlearn: 18109.3134229\ttotal: 489ms\tremaining: 2s\n",
      "59:\tlearn: 18077.4950916\ttotal: 495ms\tremaining: 1.98s\n",
      "60:\tlearn: 17974.0924185\ttotal: 509ms\tremaining: 1.99s\n",
      "61:\tlearn: 17859.0437227\ttotal: 519ms\tremaining: 1.99s\n",
      "62:\tlearn: 17747.0301936\ttotal: 530ms\tremaining: 1.99s\n",
      "63:\tlearn: 17678.3856124\ttotal: 538ms\tremaining: 1.98s\n",
      "64:\tlearn: 17588.0961252\ttotal: 544ms\tremaining: 1.97s\n",
      "65:\tlearn: 17547.0976848\ttotal: 555ms\tremaining: 1.97s\n",
      "66:\tlearn: 17456.1292968\ttotal: 564ms\tremaining: 1.96s\n",
      "67:\tlearn: 17374.7653226\ttotal: 584ms\tremaining: 1.99s\n",
      "68:\tlearn: 17287.7628810\ttotal: 598ms\tremaining: 2s\n",
      "69:\tlearn: 17220.0483773\ttotal: 604ms\tremaining: 1.98s\n",
      "70:\tlearn: 17171.7956116\ttotal: 626ms\tremaining: 2.02s\n",
      "71:\tlearn: 17092.4146981\ttotal: 636ms\tremaining: 2.01s\n",
      "72:\tlearn: 17011.0644422\ttotal: 647ms\tremaining: 2.01s\n",
      "73:\tlearn: 16950.2046318\ttotal: 651ms\tremaining: 1.99s\n",
      "74:\tlearn: 16927.6087387\ttotal: 661ms\tremaining: 1.98s\n",
      "75:\tlearn: 16903.5014021\ttotal: 665ms\tremaining: 1.96s\n",
      "76:\tlearn: 16805.7574935\ttotal: 673ms\tremaining: 1.95s\n",
      "77:\tlearn: 16658.3971320\ttotal: 680ms\tremaining: 1.94s\n",
      "78:\tlearn: 16635.8829976\ttotal: 692ms\tremaining: 1.93s\n",
      "79:\tlearn: 16523.8985075\ttotal: 697ms\tremaining: 1.92s\n",
      "80:\tlearn: 16424.3078066\ttotal: 700ms\tremaining: 1.89s\n",
      "81:\tlearn: 16324.1029329\ttotal: 710ms\tremaining: 1.89s\n",
      "82:\tlearn: 16260.5524596\ttotal: 714ms\tremaining: 1.86s\n",
      "83:\tlearn: 16162.1574949\ttotal: 723ms\tremaining: 1.86s\n",
      "84:\tlearn: 16117.3470210\ttotal: 727ms\tremaining: 1.84s\n",
      "85:\tlearn: 16081.2834965\ttotal: 731ms\tremaining: 1.82s\n",
      "86:\tlearn: 16037.1091012\ttotal: 741ms\tremaining: 1.81s\n",
      "87:\tlearn: 15997.9894435\ttotal: 745ms\tremaining: 1.79s\n",
      "88:\tlearn: 15874.2763980\ttotal: 750ms\tremaining: 1.78s\n",
      "89:\tlearn: 15751.1371142\ttotal: 757ms\tremaining: 1.76s\n",
      "90:\tlearn: 15646.1422606\ttotal: 761ms\tremaining: 1.75s\n",
      "91:\tlearn: 15588.1472789\ttotal: 768ms\tremaining: 1.74s\n",
      "92:\tlearn: 15493.1023629\ttotal: 774ms\tremaining: 1.72s\n",
      "93:\tlearn: 15386.8082333\ttotal: 782ms\tremaining: 1.71s\n",
      "94:\tlearn: 15301.1931136\ttotal: 790ms\tremaining: 1.71s\n",
      "95:\tlearn: 15200.6914377\ttotal: 804ms\tremaining: 1.71s\n",
      "96:\tlearn: 15171.8264831\ttotal: 811ms\tremaining: 1.7s\n",
      "97:\tlearn: 15153.3309889\ttotal: 822ms\tremaining: 1.69s\n",
      "98:\tlearn: 15044.4107520\ttotal: 829ms\tremaining: 1.68s\n",
      "99:\tlearn: 14950.4847063\ttotal: 838ms\tremaining: 1.68s\n",
      "100:\tlearn: 14937.8428245\ttotal: 846ms\tremaining: 1.67s\n",
      "101:\tlearn: 14859.4438151\ttotal: 852ms\tremaining: 1.65s\n",
      "102:\tlearn: 14781.8014105\ttotal: 856ms\tremaining: 1.64s\n",
      "103:\tlearn: 14770.1648419\ttotal: 866ms\tremaining: 1.63s\n",
      "104:\tlearn: 14682.1729484\ttotal: 871ms\tremaining: 1.62s\n",
      "105:\tlearn: 14587.5097876\ttotal: 877ms\tremaining: 1.6s\n",
      "106:\tlearn: 14495.7397273\ttotal: 886ms\tremaining: 1.6s\n",
      "107:\tlearn: 14407.3961846\ttotal: 893ms\tremaining: 1.59s\n",
      "108:\tlearn: 14320.2171506\ttotal: 905ms\tremaining: 1.58s\n",
      "109:\tlearn: 14237.4103584\ttotal: 919ms\tremaining: 1.59s\n",
      "110:\tlearn: 14178.9767223\ttotal: 923ms\tremaining: 1.57s\n",
      "111:\tlearn: 14083.4123183\ttotal: 938ms\tremaining: 1.57s\n",
      "112:\tlearn: 14000.6652951\ttotal: 948ms\tremaining: 1.57s\n",
      "113:\tlearn: 13924.9920682\ttotal: 955ms\tremaining: 1.56s\n",
      "114:\tlearn: 13868.3679076\ttotal: 972ms\tremaining: 1.56s\n",
      "115:\tlearn: 13801.2880287\ttotal: 992ms\tremaining: 1.57s\n",
      "116:\tlearn: 13711.7890286\ttotal: 1.01s\tremaining: 1.58s\n",
      "117:\tlearn: 13644.4988213\ttotal: 1.03s\tremaining: 1.59s\n",
      "118:\tlearn: 13578.2651562\ttotal: 1.05s\tremaining: 1.6s\n",
      "119:\tlearn: 13486.7775108\ttotal: 1.06s\tremaining: 1.6s\n",
      "120:\tlearn: 13429.9740185\ttotal: 1.07s\tremaining: 1.59s\n",
      "121:\tlearn: 13369.3355600\ttotal: 1.09s\tremaining: 1.59s\n",
      "122:\tlearn: 13308.6795204\ttotal: 1.12s\tremaining: 1.61s\n",
      "123:\tlearn: 13228.1359668\ttotal: 1.13s\tremaining: 1.61s\n",
      "124:\tlearn: 13156.8040247\ttotal: 1.15s\tremaining: 1.61s\n",
      "125:\tlearn: 13110.5320329\ttotal: 1.16s\tremaining: 1.59s\n",
      "126:\tlearn: 13043.4311375\ttotal: 1.17s\tremaining: 1.59s\n",
      "127:\tlearn: 12947.6388376\ttotal: 1.19s\tremaining: 1.6s\n",
      "128:\tlearn: 12880.6840146\ttotal: 1.2s\tremaining: 1.59s\n",
      "129:\tlearn: 12830.8250559\ttotal: 1.21s\tremaining: 1.59s\n",
      "130:\tlearn: 12719.7986267\ttotal: 1.23s\tremaining: 1.59s\n",
      "131:\tlearn: 12669.8659918\ttotal: 1.25s\tremaining: 1.59s\n",
      "132:\tlearn: 12634.0781112\ttotal: 1.26s\tremaining: 1.58s\n",
      "133:\tlearn: 12579.2704729\ttotal: 1.27s\tremaining: 1.58s\n",
      "134:\tlearn: 12528.9573084\ttotal: 1.28s\tremaining: 1.56s\n",
      "135:\tlearn: 12471.6106591\ttotal: 1.3s\tremaining: 1.57s\n",
      "136:\tlearn: 12447.8814919\ttotal: 1.31s\tremaining: 1.56s\n",
      "137:\tlearn: 12367.9796936\ttotal: 1.33s\tremaining: 1.56s\n",
      "138:\tlearn: 12351.9047817\ttotal: 1.34s\tremaining: 1.55s\n",
      "139:\tlearn: 12286.2510781\ttotal: 1.35s\tremaining: 1.54s\n",
      "140:\tlearn: 12273.8059221\ttotal: 1.36s\tremaining: 1.53s\n",
      "141:\tlearn: 12219.7765872\ttotal: 1.37s\tremaining: 1.53s\n",
      "142:\tlearn: 12181.7726567\ttotal: 1.38s\tremaining: 1.52s\n",
      "143:\tlearn: 12141.6285136\ttotal: 1.39s\tremaining: 1.51s\n",
      "144:\tlearn: 12093.9650617\ttotal: 1.4s\tremaining: 1.5s\n",
      "145:\tlearn: 12062.1189966\ttotal: 1.41s\tremaining: 1.49s\n",
      "146:\tlearn: 11997.1148519\ttotal: 1.42s\tremaining: 1.48s\n",
      "147:\tlearn: 11934.0058659\ttotal: 1.43s\tremaining: 1.47s\n",
      "148:\tlearn: 11903.9525750\ttotal: 1.44s\tremaining: 1.46s\n",
      "149:\tlearn: 11802.2325694\ttotal: 1.45s\tremaining: 1.45s\n",
      "150:\tlearn: 11748.8366140\ttotal: 1.46s\tremaining: 1.44s\n",
      "151:\tlearn: 11712.1158263\ttotal: 1.46s\tremaining: 1.42s\n",
      "152:\tlearn: 11639.8900712\ttotal: 1.47s\tremaining: 1.41s\n",
      "153:\tlearn: 11597.9872157\ttotal: 1.48s\tremaining: 1.4s\n",
      "154:\tlearn: 11578.8337514\ttotal: 1.49s\tremaining: 1.39s\n",
      "155:\tlearn: 11516.8378951\ttotal: 1.5s\tremaining: 1.38s\n",
      "156:\tlearn: 11511.5041950\ttotal: 1.5s\tremaining: 1.37s\n",
      "157:\tlearn: 11469.7391077\ttotal: 1.51s\tremaining: 1.36s\n",
      "158:\tlearn: 11464.9554772\ttotal: 1.52s\tremaining: 1.35s\n",
      "159:\tlearn: 11393.4215716\ttotal: 1.52s\tremaining: 1.33s\n",
      "160:\tlearn: 11363.8289168\ttotal: 1.53s\tremaining: 1.32s\n",
      "161:\tlearn: 11329.6339467\ttotal: 1.54s\tremaining: 1.31s\n",
      "162:\tlearn: 11272.7640232\ttotal: 1.54s\tremaining: 1.3s\n",
      "163:\tlearn: 11195.8662052\ttotal: 1.55s\tremaining: 1.29s\n",
      "164:\tlearn: 11173.1092629\ttotal: 1.55s\tremaining: 1.27s\n",
      "165:\tlearn: 11138.4877213\ttotal: 1.56s\tremaining: 1.26s\n",
      "166:\tlearn: 11097.8097380\ttotal: 1.57s\tremaining: 1.25s\n",
      "167:\tlearn: 11077.2757522\ttotal: 1.58s\tremaining: 1.24s\n",
      "168:\tlearn: 11032.9129220\ttotal: 1.58s\tremaining: 1.23s\n",
      "169:\tlearn: 10986.3478338\ttotal: 1.59s\tremaining: 1.22s\n",
      "170:\tlearn: 10924.4749583\ttotal: 1.6s\tremaining: 1.21s\n",
      "171:\tlearn: 10883.2342670\ttotal: 1.61s\tremaining: 1.2s\n",
      "172:\tlearn: 10853.5067649\ttotal: 1.62s\tremaining: 1.19s\n",
      "173:\tlearn: 10797.9971393\ttotal: 1.63s\tremaining: 1.18s\n",
      "174:\tlearn: 10771.0009685\ttotal: 1.63s\tremaining: 1.17s\n",
      "175:\tlearn: 10717.2732312\ttotal: 1.64s\tremaining: 1.16s\n",
      "176:\tlearn: 10677.9764797\ttotal: 1.65s\tremaining: 1.14s\n",
      "177:\tlearn: 10627.0464280\ttotal: 1.65s\tremaining: 1.13s\n",
      "178:\tlearn: 10594.1349104\ttotal: 1.66s\tremaining: 1.12s\n",
      "179:\tlearn: 10557.1532354\ttotal: 1.67s\tremaining: 1.11s\n",
      "180:\tlearn: 10495.3813401\ttotal: 1.68s\tremaining: 1.1s\n",
      "181:\tlearn: 10447.2760642\ttotal: 1.68s\tremaining: 1.09s\n",
      "182:\tlearn: 10421.5042859\ttotal: 1.69s\tremaining: 1.08s\n",
      "183:\tlearn: 10408.4922502\ttotal: 1.69s\tremaining: 1.07s\n",
      "184:\tlearn: 10367.8698735\ttotal: 1.7s\tremaining: 1.05s\n",
      "185:\tlearn: 10337.2508886\ttotal: 1.71s\tremaining: 1.04s\n",
      "186:\tlearn: 10320.6611722\ttotal: 1.71s\tremaining: 1.03s\n",
      "187:\tlearn: 10310.1004824\ttotal: 1.72s\tremaining: 1.02s\n",
      "188:\tlearn: 10268.6447962\ttotal: 1.72s\tremaining: 1.01s\n",
      "189:\tlearn: 10208.6984668\ttotal: 1.73s\tremaining: 1s\n",
      "190:\tlearn: 10165.5477524\ttotal: 1.73s\tremaining: 990ms\n",
      "191:\tlearn: 10132.2344701\ttotal: 1.74s\tremaining: 979ms\n",
      "192:\tlearn: 10088.9988577\ttotal: 1.74s\tremaining: 967ms\n",
      "193:\tlearn: 10086.1680719\ttotal: 1.75s\tremaining: 958ms\n",
      "194:\tlearn: 10072.8880131\ttotal: 1.76s\tremaining: 948ms\n",
      "195:\tlearn: 10023.3869668\ttotal: 1.77s\tremaining: 939ms\n",
      "196:\tlearn: 9982.5864904\ttotal: 1.77s\tremaining: 928ms\n",
      "197:\tlearn: 9929.9414546\ttotal: 1.78s\tremaining: 918ms\n",
      "198:\tlearn: 9927.3965447\ttotal: 1.79s\tremaining: 908ms\n",
      "199:\tlearn: 9878.9227878\ttotal: 1.8s\tremaining: 898ms\n",
      "200:\tlearn: 9825.7428162\ttotal: 1.8s\tremaining: 889ms\n",
      "201:\tlearn: 9794.8568388\ttotal: 1.81s\tremaining: 880ms\n",
      "202:\tlearn: 9752.9935606\ttotal: 1.82s\tremaining: 870ms\n",
      "203:\tlearn: 9722.5016744\ttotal: 1.83s\tremaining: 862ms\n",
      "204:\tlearn: 9717.3312508\ttotal: 1.84s\tremaining: 852ms\n",
      "205:\tlearn: 9684.0683067\ttotal: 1.84s\tremaining: 840ms\n",
      "206:\tlearn: 9651.7014934\ttotal: 1.85s\tremaining: 832ms\n",
      "207:\tlearn: 9613.4181558\ttotal: 1.86s\tremaining: 822ms\n",
      "208:\tlearn: 9583.9421644\ttotal: 1.87s\tremaining: 814ms\n",
      "209:\tlearn: 9528.8873713\ttotal: 1.87s\tremaining: 803ms\n",
      "210:\tlearn: 9497.7820371\ttotal: 1.88s\tremaining: 795ms\n",
      "211:\tlearn: 9482.9590006\ttotal: 1.89s\tremaining: 784ms\n",
      "212:\tlearn: 9441.4706742\ttotal: 1.89s\tremaining: 773ms\n",
      "213:\tlearn: 9391.2672633\ttotal: 1.9s\tremaining: 763ms\n",
      "214:\tlearn: 9347.1275468\ttotal: 1.9s\tremaining: 753ms\n",
      "215:\tlearn: 9301.8306151\ttotal: 1.91s\tremaining: 743ms\n",
      "216:\tlearn: 9299.6360713\ttotal: 1.92s\tremaining: 733ms\n",
      "217:\tlearn: 9264.5062973\ttotal: 1.92s\tremaining: 722ms\n",
      "218:\tlearn: 9244.3581522\ttotal: 1.93s\tremaining: 713ms\n",
      "219:\tlearn: 9214.4132239\ttotal: 1.93s\tremaining: 703ms\n",
      "220:\tlearn: 9183.4001159\ttotal: 1.94s\tremaining: 692ms\n",
      "221:\tlearn: 9132.0714476\ttotal: 1.94s\tremaining: 683ms\n",
      "222:\tlearn: 9097.6567202\ttotal: 1.95s\tremaining: 674ms\n",
      "223:\tlearn: 9054.9865265\ttotal: 1.96s\tremaining: 664ms\n",
      "224:\tlearn: 9034.8429250\ttotal: 1.97s\tremaining: 656ms\n",
      "225:\tlearn: 8993.2421676\ttotal: 1.97s\tremaining: 647ms\n",
      "226:\tlearn: 8972.9663955\ttotal: 1.98s\tremaining: 638ms\n",
      "227:\tlearn: 8954.7102111\ttotal: 1.99s\tremaining: 629ms\n",
      "228:\tlearn: 8926.8527596\ttotal: 2s\tremaining: 620ms\n",
      "229:\tlearn: 8906.5949185\ttotal: 2.01s\tremaining: 613ms\n",
      "230:\tlearn: 8891.9109797\ttotal: 2.02s\tremaining: 604ms\n",
      "231:\tlearn: 8854.1490641\ttotal: 2.03s\tremaining: 595ms\n",
      "232:\tlearn: 8831.1304525\ttotal: 2.04s\tremaining: 585ms\n",
      "233:\tlearn: 8787.0387566\ttotal: 2.05s\tremaining: 577ms\n",
      "234:\tlearn: 8760.1643507\ttotal: 2.05s\tremaining: 568ms\n",
      "235:\tlearn: 8757.8019194\ttotal: 2.06s\tremaining: 559ms\n",
      "236:\tlearn: 8720.8889408\ttotal: 2.06s\tremaining: 549ms\n",
      "237:\tlearn: 8677.6038150\ttotal: 2.07s\tremaining: 539ms\n",
      "238:\tlearn: 8652.5867204\ttotal: 2.08s\tremaining: 530ms\n",
      "239:\tlearn: 8634.0846329\ttotal: 2.08s\tremaining: 520ms\n",
      "240:\tlearn: 8611.4868234\ttotal: 2.09s\tremaining: 511ms\n",
      "241:\tlearn: 8580.1808709\ttotal: 2.09s\tremaining: 502ms\n",
      "242:\tlearn: 8545.7454975\ttotal: 2.1s\tremaining: 492ms\n",
      "243:\tlearn: 8528.5354552\ttotal: 2.1s\tremaining: 483ms\n",
      "244:\tlearn: 8526.9498596\ttotal: 2.11s\tremaining: 473ms\n",
      "245:\tlearn: 8493.2255381\ttotal: 2.11s\tremaining: 464ms\n",
      "246:\tlearn: 8456.3775989\ttotal: 2.12s\tremaining: 454ms\n",
      "247:\tlearn: 8432.3694756\ttotal: 2.12s\tremaining: 445ms\n",
      "248:\tlearn: 8430.8345734\ttotal: 2.13s\tremaining: 436ms\n",
      "249:\tlearn: 8413.6257316\ttotal: 2.13s\tremaining: 427ms\n",
      "250:\tlearn: 8367.3926427\ttotal: 2.14s\tremaining: 418ms\n",
      "251:\tlearn: 8340.8113994\ttotal: 2.15s\tremaining: 410ms\n",
      "252:\tlearn: 8308.0496975\ttotal: 2.16s\tremaining: 401ms\n",
      "253:\tlearn: 8292.6938051\ttotal: 2.17s\tremaining: 392ms\n",
      "254:\tlearn: 8280.7636049\ttotal: 2.17s\tremaining: 384ms\n",
      "255:\tlearn: 8256.0516670\ttotal: 2.18s\tremaining: 375ms\n",
      "256:\tlearn: 8215.6229226\ttotal: 2.19s\tremaining: 367ms\n",
      "257:\tlearn: 8193.5976328\ttotal: 2.21s\tremaining: 359ms\n",
      "258:\tlearn: 8181.8353289\ttotal: 2.21s\tremaining: 350ms\n",
      "259:\tlearn: 8180.0424531\ttotal: 2.22s\tremaining: 341ms\n",
      "260:\tlearn: 8150.7551846\ttotal: 2.22s\tremaining: 332ms\n",
      "261:\tlearn: 8123.0845062\ttotal: 2.23s\tremaining: 324ms\n",
      "262:\tlearn: 8104.8010238\ttotal: 2.24s\tremaining: 315ms\n",
      "263:\tlearn: 8087.9735665\ttotal: 2.24s\tremaining: 306ms\n",
      "264:\tlearn: 8076.5512642\ttotal: 2.25s\tremaining: 297ms\n",
      "265:\tlearn: 8043.4445075\ttotal: 2.25s\tremaining: 288ms\n",
      "266:\tlearn: 8027.6921812\ttotal: 2.26s\tremaining: 280ms\n",
      "267:\tlearn: 8013.7634836\ttotal: 2.27s\tremaining: 271ms\n",
      "268:\tlearn: 7979.0281734\ttotal: 2.27s\tremaining: 262ms\n",
      "269:\tlearn: 7946.5577497\ttotal: 2.28s\tremaining: 253ms\n",
      "270:\tlearn: 7915.4525907\ttotal: 2.28s\tremaining: 244ms\n",
      "271:\tlearn: 7913.9241674\ttotal: 2.29s\tremaining: 236ms\n",
      "272:\tlearn: 7912.3067937\ttotal: 2.3s\tremaining: 227ms\n",
      "273:\tlearn: 7898.8084130\ttotal: 2.3s\tremaining: 219ms\n",
      "274:\tlearn: 7887.7587836\ttotal: 2.31s\tremaining: 210ms\n",
      "275:\tlearn: 7876.1117807\ttotal: 2.33s\tremaining: 203ms\n",
      "276:\tlearn: 7848.2549665\ttotal: 2.34s\tremaining: 194ms\n",
      "277:\tlearn: 7838.9558554\ttotal: 2.35s\tremaining: 186ms\n",
      "278:\tlearn: 7795.5861503\ttotal: 2.36s\tremaining: 178ms\n",
      "279:\tlearn: 7788.8692135\ttotal: 2.37s\tremaining: 169ms\n",
      "280:\tlearn: 7765.8205923\ttotal: 2.38s\tremaining: 161ms\n",
      "281:\tlearn: 7759.5906074\ttotal: 2.39s\tremaining: 153ms\n",
      "282:\tlearn: 7757.4907738\ttotal: 2.4s\tremaining: 144ms\n",
      "283:\tlearn: 7730.7269261\ttotal: 2.41s\tremaining: 136ms\n",
      "284:\tlearn: 7715.5363705\ttotal: 2.41s\tremaining: 127ms\n",
      "285:\tlearn: 7695.8497016\ttotal: 2.42s\tremaining: 119ms\n",
      "286:\tlearn: 7669.2962960\ttotal: 2.43s\tremaining: 110ms\n",
      "287:\tlearn: 7636.9363978\ttotal: 2.44s\tremaining: 102ms\n",
      "288:\tlearn: 7623.5454047\ttotal: 2.45s\tremaining: 93.1ms\n",
      "289:\tlearn: 7585.1070448\ttotal: 2.46s\tremaining: 84.9ms\n",
      "290:\tlearn: 7572.6241287\ttotal: 2.47s\tremaining: 76.4ms\n",
      "291:\tlearn: 7549.1421262\ttotal: 2.47s\tremaining: 67.8ms\n",
      "292:\tlearn: 7524.0464217\ttotal: 2.48s\tremaining: 59.2ms\n",
      "293:\tlearn: 7501.4745836\ttotal: 2.48s\tremaining: 50.7ms\n",
      "294:\tlearn: 7484.2543355\ttotal: 2.49s\tremaining: 42.2ms\n",
      "295:\tlearn: 7463.1637291\ttotal: 2.5s\tremaining: 33.8ms\n",
      "296:\tlearn: 7457.5740752\ttotal: 2.5s\tremaining: 25.3ms\n",
      "297:\tlearn: 7440.8296031\ttotal: 2.51s\tremaining: 16.8ms\n",
      "298:\tlearn: 7425.9281964\ttotal: 2.51s\tremaining: 8.41ms\n",
      "299:\tlearn: 7395.8563889\ttotal: 2.52s\tremaining: 0us\n",
      "error: 0.05489651607687459\n"
     ]
    }
   ],
   "source": [
    "from cgi import test\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from altair import Column\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder,TargetEncoder\n",
    "from scipy.stats import ttest_ind\n",
    "import shap\n",
    "import catboost as cat\n",
    "\n",
    "from sklearn import pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor, make_column_selector\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.feature_selection import f_regression, chi2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# init js\n",
    "shap.initjs()\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Устанавливаем вывод pandas в удобочитаемый формат\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Настройка вывода pandas через sklearn\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Игнорируем предупреждения\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('test.csv')\n",
    "\n",
    "x_train_X=train.drop(['SalePrice'],axis=1)\n",
    "y_train_y=train['SalePrice']\n",
    "y_train_ylog=np.log1p (train['SalePrice'])\n",
    "\n",
    "\n",
    "class mypreprocess(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.nanistype=[\n",
    "            'Alley',\n",
    "            'BsmtQual',\n",
    "            'BsmtCond',\n",
    "            'BsmtExposure',\n",
    "            'BsmtFinType1',\n",
    "            'BsmtFinType2',\n",
    "            'FireplaceQu',\n",
    "            'GarageType',\n",
    "            'GarageFinish',\n",
    "            'GarageQual',\n",
    "            'GarageCond',\n",
    "            'PoolQC',\n",
    "            'Fence',\n",
    "            'MiscFeature',\n",
    "            'MasVnrType'\n",
    "        ]\n",
    "        self.rendict={\n",
    "            'name':'MSSubClass',\n",
    "            20: '1-STORY 1946 & NEWER ALL STYLES',\n",
    "            30: '1-STORY 1945 & OLDER',\n",
    "            40: '1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "            45: '1-1/2 STORY - UNFINISHED ALL AGES',\n",
    "            50: '1-1/2 STORY FINISHED ALL AGES',\n",
    "            60: '2-STORY 1946 & NEWER',\n",
    "            70: '2-STORY 1945 & OLDER',\n",
    "            75: '2-1/2 STORY ALL AGES',\n",
    "            80: 'SPLIT OR MULTI-LEVEL',\n",
    "            85: 'SPLIT FOYER',\n",
    "            90: 'DUPLEX - ALL STYLES AND AGES',\n",
    "            120: '1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
    "            150: '1-1/2 STORY PUD - ALL AGES',\n",
    "            160: '2-STORY PUD - 1946 & NEWER',\n",
    "            180: 'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
    "            190: '2 FAMILY CONVERSION - ALL STYLES AND AGES'\n",
    "        }\n",
    "\n",
    "    def preprocess( self, df):\n",
    "       \n",
    "        df[self.rendict['name']]=df[self.rendict['name']].map( self.rendict)    \n",
    "        df[ self.nanistype]=df[self.nanistype].fillna('Empty')\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.preprocess(X)\n",
    "\n",
    "def show_nan_count(train):\n",
    "    d=pd.DataFrame(data={'NaN_count': train.isna().sum(), 'data_type': train.dtypes}).T\n",
    "    filtered_columns = d.columns[d.loc['NaN_count'] > 0]\n",
    "    filtered_df = d[filtered_columns]\n",
    "    return filtered_df\n",
    "\n",
    "#drop_features = ['Id','Alley','MasVnrType','FireplaceQu','PoolQC','Fence','MiscFeature','LandSlope','GarageQual','GarageCond','MiscVal','Utilities','YrSold', 'MSSubClass','OverallCond', 'LowQualFinSF', 'MiscVal', 'BsmtHalfBath', '3SsnPorch', 'MoSold', 'PoolArea']\n",
    "drop_features=['Id']\n",
    "firimputer= ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mypreprocess', mypreprocess(), x_train_X.columns)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "my_imputer = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('drop_features', 'drop', drop_features),\n",
    "        ('num_imputer', KNNImputer(n_neighbors=5), make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent'), make_column_selector(dtype_include='object'))\n",
    "    ],\n",
    "    verbose_feature_names_out = False,\n",
    "    remainder = 'passthrough'\n",
    ") \n",
    "scaler_and_encoder = ColumnTransformer(\n",
    "    [\n",
    "        ('target_encoding', TargetEncoder(), make_column_selector(dtype_include='object')),\n",
    "        ('scaling_num_columns', StandardScaler(), make_column_selector(dtype_include=['float64', 'int64']))\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "prepreprocessor = Pipeline(\n",
    "    [\n",
    "        ('firimputer', firimputer),\n",
    "        ('imputer', my_imputer),\n",
    "        ('scaler_and_encoder', scaler_and_encoder),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pretrain_X = prepreprocessor.fit_transform(x_train_X,y_train_ylog)\n",
    "pretrain_y = y_train_ylog\n",
    "\n",
    "randomseed = 42\n",
    "def rmse(y_true, y_pred):\n",
    "    return -np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# Создание кастомной метрики для использования в cross_val_score\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def objectiveknn(trial):\n",
    "    params = {'n_neighbors': trial.suggest_int('n_neighbors', 1, 10)}\n",
    "    model = KNeighborsRegressor(**params)\n",
    "    scores =  cross_val_score(model, pretrain_X, pretrain_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "\n",
    "def objectivelasso(trial):\n",
    "    params = {'alpha': trial.suggest_float('alpha', 0.0, 1.0)}\n",
    "    model = Lasso(**params)\n",
    "    scores =  cross_val_score(model, pretrain_X, pretrain_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "\n",
    "def objectiveRidge(trial):\n",
    "    params = {'alpha': trial.suggest_float('alpha', 0.0, 1.0)}\n",
    "    model = Ridge(**params)\n",
    "    scores =  cross_val_score(model, pretrain_X, pretrain_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "\n",
    "def ojectiveRandomForest(trial):\n",
    "    params = {'n_estimators': trial.suggest_int('n_estimators', 3, 10),\n",
    "              'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "              'min_samples_split': trial.suggest_int('min_samples_split', 2, 7)}\n",
    "    model = RandomForestRegressor(**params)\n",
    "    scores =  cross_val_score(model, pretrain_X, pretrain_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# studyknn = optuna.create_study(direction='minimize')\n",
    "# studylasso = optuna.create_study(direction='minimize')\n",
    "# studyRidge = optuna.create_study(direction='minimize')\n",
    "# studyRandomForest = optuna.create_study(direction='minimize')\n",
    "# studylasso.optimize(objectivelasso, n_trials=10)\n",
    "# studyknn.optimize(objectiveknn, n_trials=10)\n",
    "# studyRidge.optimize(objectiveRidge, n_trials=10)\n",
    "# studyRandomForest.optimize(ojectiveRandomForest, n_trials=1)\n",
    "\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        ('firimputer', firimputer),\n",
    "        ('imputer', my_imputer),\n",
    "        ('scaler_and_encoder', scaler_and_encoder),\n",
    "    ]\n",
    ")\n",
    "def gettt(model):\n",
    "    return TransformedTargetRegressor(regressor=model, func=np.expm1, inverse_func=np.log1p)\n",
    "cb =gettt(cat.CatBoostRegressor(random_seed=randomseed,iterations=30))\n",
    "rf = gettt(RandomForestRegressor(**studyRandomForest.best_params))\n",
    "las=gettt(Lasso(**studylasso.best_params))\n",
    "ridge=gettt(Ridge(**studyRidge.best_params))\n",
    "knn = gettt(KNeighborsRegressor( **studyknn.best_params))\n",
    "\n",
    "train_X = preprocessor.fit_transform(x_train_X,y_train_ylog)\n",
    "train_y = y_train_ylog\n",
    "train_X,test_X,train_y,test_y = train_test_split(train_X, train_y, test_size=0.3,random_state=42)\n",
    "\n",
    "predcb=cb.fit(train_X,train_y).predict(test_X)\n",
    "predrf=rf.fit(train_X,train_y).predict(test_X)\n",
    "predlas=las.fit(train_X,train_y).predict(test_X)\n",
    "predridge=ridge.fit(train_X,train_y).predict(test_X)\n",
    "predknn=knn.fit(train_X,train_y).predict(test_X)\n",
    "\n",
    "def ojectiveweights(trial):\n",
    "    cbweight = trial.suggest_float('cbweight', 0.0, 10.0)\n",
    "    rfweight = trial.suggest_float('rfweight', 0.0, 10.0)\n",
    "    lasweight = trial.suggest_float('lasweight', 0.0, 10.0)\n",
    "    ridgeweight = trial.suggest_float('ridgeweight', 0.0, 10.0)\n",
    "    knnweight = trial.suggest_float('knnweight', 0.0, 10.0)\n",
    "    pred= (cbweight*predcb+rfweight*predrf+lasweight*predlas+ridgeweight*predridge+knnweight*predknn)/(cbweight+rfweight+lasweight+ridgeweight+knnweight)\n",
    "    return rmse(test_y, pred)\n",
    "\n",
    "studyweights = optuna.create_study(direction='minimize')\n",
    "studyweights.optimize(ojectiveweights, n_trials=10)\n",
    "weights=[studyweights.best_params['cbweight'],studyweights.best_params['rfweight'],studyweights.best_params['lasweight'],studyweights.best_params['ridgeweight'],studyweights.best_params['knnweight']]\n",
    "v = VotingRegressor(estimators=[('cb', cb), ('rf', rf), ('las', las), ('ridge', ridge), ('knn', knn)], weights=weights)\n",
    "# Создание и обучение модели с логарифмическим преобразованием целевой переменной\n",
    "ml_pipeline_log = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model_log', v)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ml_pipeline_log.fit(train_X,train_y)\n",
    "\n",
    "pred = ml_pipeline_log.predict(test_X) \n",
    "-rmse(test_y, pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181     200100\n",
       "1184    186700\n",
       "1059    220000\n",
       "350     318061\n",
       "911     143500\n",
       "         ...  \n",
       "236     185500\n",
       "115     176000\n",
       "87      164500\n",
       "323     126175\n",
       "709     109900\n",
       "Name: SalePrice, Length: 438, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190422.01647212, 192521.04152563, 213182.47312097, 315280.2611552 ,\n",
       "       150848.60026469, 178587.31116175, 282420.85089104, 153077.19096346,\n",
       "       149402.6409096 , 123856.60641709, 144303.78534595, 315839.17249978,\n",
       "       135303.62845019, 107698.39312883, 175444.85134685, 192218.66701229,\n",
       "       221577.28811889, 307539.49474055, 129257.20958524, 120972.65728537,\n",
       "       265758.91670666, 125054.93495486, 146365.78086947, 136421.0032453 ,\n",
       "       211210.9543149 , 132834.68721107, 147251.69431061,  84148.6948791 ,\n",
       "       165520.19241961, 145671.04414003, 126739.91686454, 157527.12433083,\n",
       "       121305.0336352 , 243138.59573055, 132947.21981532, 175718.95786953,\n",
       "       194011.03361803, 164211.52596297,  86349.52539406, 574802.08933995,\n",
       "       138923.7112835 , 219407.43596529, 136837.71496232, 108530.79929219,\n",
       "       244660.8314915 , 257135.02556715, 191740.93842574, 436528.53077526,\n",
       "       261963.14693246, 185996.00521973, 158749.0355518 , 183287.68432418,\n",
       "       138498.46568712,  93253.28341037, 151709.11435226, 128714.46154531,\n",
       "       109348.64109573, 132565.44107302,  85233.03759736, 149300.68019685,\n",
       "       111906.48588061, 194271.23367047, 291613.80911624, 268552.62091362,\n",
       "       234788.64763712, 164728.26498442, 629237.55751899, 177057.21638702,\n",
       "       153683.43372364, 141815.0111933 , 165132.96452713, 137811.13586938,\n",
       "        98275.99027793, 279607.08629269, 601018.88407857, 101799.47246425,\n",
       "       292809.94976233, 148904.82327874, 271511.25047812, 172302.64821454,\n",
       "       142648.59453239, 148103.51056879, 236006.27955898, 113744.83061871,\n",
       "       115947.08357819, 138124.10842224, 102945.85707135, 121383.87163297,\n",
       "       242827.2341529 ,  93300.78190383, 129399.50191109, 190118.30016505,\n",
       "       204986.86923045, 101796.43782983, 119620.30049006, 128810.40313112,\n",
       "        95493.67647839, 412235.19407305, 129445.12760074, 168948.33491224,\n",
       "       116310.26633835, 140978.53161661,  96493.6937782 , 175799.12077751,\n",
       "       212128.34255908,  83248.96348455, 109365.42057853, 152654.95542693,\n",
       "       131949.7032411 , 158043.62728107, 178053.12121818, 165036.97373713,\n",
       "       153137.66053686, 145688.09239362, 157606.66678049, 154478.66761285,\n",
       "       161255.23113586, 314989.89117245, 134624.9017834 , 179155.57040963,\n",
       "       106164.29534404, 194471.40061948, 157092.00310452, 182121.50070431,\n",
       "       110839.40021342, 129968.69324847,  99084.22783132, 172139.85454954,\n",
       "        86584.09303877, 190182.0543416 , 136023.01500442, 175403.49056013,\n",
       "       126520.80177414, 119055.42709173, 227279.96995756, 225162.57505166,\n",
       "       126408.27187841, 139553.73752009, 378034.5854869 , 135763.80634294,\n",
       "       172951.60735472, 188174.90210311, 171420.01984059, 116915.62361012,\n",
       "       100743.9627896 , 238732.28080048, 139665.15143598, 131863.91883158,\n",
       "       104158.99214737, 159445.50272443, 118561.380285  , 188222.48750609,\n",
       "       113475.66236132, 271330.30181316, 162161.73604787, 119578.14154894,\n",
       "       208491.82704414, 119934.05188659, 221407.49054342, 135493.97252199,\n",
       "       163143.65498256, 196230.72424017, 124702.51881693,  76865.28038343,\n",
       "       267874.94927178, 270464.36798595, 237917.90583313, 206538.68673322,\n",
       "       125227.48623355,  45029.08890145, 137494.51346913, 153024.62082881,\n",
       "       183245.16970791, 214111.52910363, 343397.16466209, 135155.73493802,\n",
       "       175448.85834091, 187354.79841965, 171038.77242625, 157886.93732036,\n",
       "       120401.63402728, 268649.84132434, 160021.80185788, 169303.3414497 ,\n",
       "       142319.08793527,  49355.42821477, 179901.51751568, 201342.5002016 ,\n",
       "       328331.30558393, 145204.06455564, 191956.45763982, 313571.11412341,\n",
       "       119993.44170213, 273090.15047922, 132295.96340831, 126059.10770644,\n",
       "       159380.35932788, 338912.99740224, 183017.49258066, 132147.08978439,\n",
       "       196989.60623768, 425857.35934796, 220379.59565594, 257570.4352252 ,\n",
       "       145993.66336698, 171852.19418292, 327734.80299189, 273798.96766325,\n",
       "       182268.5893163 , 293721.95706611, 219709.32190629, 256417.11471552,\n",
       "       145535.88692283, 104006.40420739, 210762.05495874, 169399.38755282,\n",
       "       216141.59457229, 220827.29849021, 218677.67784006, 121951.71089888,\n",
       "       110936.90584732, 225256.34901459, 205464.10108386, 200678.73884104,\n",
       "       151169.85185492,  97767.54247106, 152067.44344281, 119362.03736956,\n",
       "       140461.52214287, 158948.72670544, 207693.56889674, 127324.58995036,\n",
       "       150619.52474546, 135465.70934026, 252558.13604495,  93880.52678634,\n",
       "       120867.17515735, 172342.30451964,  77601.10453486, 217221.22736873,\n",
       "       120058.95318203, 204290.79400276, 243061.1373128 , 110134.14235862,\n",
       "       310896.93132474,  89766.31182618, 114388.90318554, 169515.58548793,\n",
       "       259423.50271645, 134995.43837305, 192685.54091252, 153145.11348439,\n",
       "       120375.32913168, 117327.76613095, 116613.6145162 , 193468.99461284,\n",
       "       132819.58329758, 202074.41754534, 202399.97312013, 192032.58095908,\n",
       "       139891.1653717 , 216855.60520385, 177126.36554041,  93984.24337186,\n",
       "       247925.70169227, 126122.71506587, 184040.25334317, 101252.71784685,\n",
       "       221449.26531991, 295980.62514055, 146003.87490778,  76479.33797507,\n",
       "       119671.42885881, 132192.37567638, 290209.20761692,  98487.09926968,\n",
       "       186972.1337713 , 457142.80850509, 126799.80004927, 139824.72200476,\n",
       "       109255.26185401, 269047.93739294, 307232.22055511, 175497.30023806,\n",
       "       181797.47164662, 497771.68073062, 209379.0009488 , 109220.34070965,\n",
       "       151251.72066364, 237422.19835458, 264081.1271245 ,  74765.98362158,\n",
       "       145656.65649045, 124648.11463145, 163438.96356825, 200574.9299783 ,\n",
       "       204982.66907358,  93469.62370755, 154755.44893388, 163705.81932595,\n",
       "       122756.05946717,  88739.48711424, 155397.6434939 , 192029.11321266,\n",
       "       170781.98723905, 198489.83123179, 139734.41382746, 318955.36783178,\n",
       "       553002.77586594, 151852.44509623, 216633.98478904, 145032.36574968,\n",
       "       179592.40913299, 157302.93611845, 114732.26516199, 129557.98164819,\n",
       "       107551.53633189, 176364.18782217, 121206.38148379, 134316.00863597,\n",
       "       150657.67005474, 148174.92438442, 143385.99703443, 135835.27999239,\n",
       "       149046.52437645, 172478.41334069, 224098.86730583, 196756.51408399,\n",
       "       184241.02460517, 538111.67329688,  94045.84244164, 137735.96894827,\n",
       "       182957.66033046, 171593.05139248, 149877.83541367, 183968.32485984,\n",
       "       324984.52117077, 190630.81946169, 125474.51546486, 221232.64321535,\n",
       "       139349.76602381, 121531.75584042, 146059.47756991, 119649.35456613,\n",
       "       114532.64668824, 146332.22344068,  78670.52439676, 172335.90760376,\n",
       "       174157.60182891, 142679.39676711, 136550.04539936, 102594.98571921,\n",
       "        94509.35336751, 179861.27063472, 157887.79364268,  92642.81700633,\n",
       "       180622.93205857, 114390.60569331, 245805.59137433, 252927.774963  ,\n",
       "       117853.45082394, 279935.08011342, 137057.03867365, 134719.81478942,\n",
       "       212662.29982819, 151627.09196786, 112183.23334239, 171770.41025971,\n",
       "       149291.237579  , 173219.27625181, 109419.91686712, 306714.57075067,\n",
       "       137663.14268294, 270083.14597304, 129389.19274371, 172674.86034458,\n",
       "       129666.07585553, 152163.11487748,  85478.53071687, 107095.75417957,\n",
       "       232522.25629317, 101640.0085246 , 289614.42121705, 169279.29940467,\n",
       "       245621.90330146, 264124.21375523, 108619.26833735, 154037.9215088 ,\n",
       "       242045.70890305, 123272.55228303, 390412.96356345, 173761.28277163,\n",
       "       321332.78037496, 228125.51452537, 226265.40446389, 133299.69712336,\n",
       "       225008.46101891, 158989.29453913, 315930.41443045, 170891.78304149,\n",
       "       150218.56631047, 191398.69828601, 126138.55038213, 332622.214373  ,\n",
       "       207127.45550799, 204168.71826264, 102070.02173595, 112123.85348042,\n",
       "       204057.32095274, 111013.16215131, 170856.69032472, 100528.90033475,\n",
       "       142583.87158535, 142455.37011952, 157626.59088525, 250733.00244858,\n",
       "       106451.69801946, 121273.26073405, 212862.82815109, 217543.18430562,\n",
       "       336510.41583929, 147048.92257356, 241054.56762356, 183763.84909327,\n",
       "       200977.66428385, 286963.15294865, 191497.64402582, 192997.44529031,\n",
       "       322274.11488014, 245116.27344444, 751503.74070278, 162407.64669898,\n",
       "       243277.14725164, 184966.03126208, 169780.69152054, 169431.80474691,\n",
       "       130173.80543695, 114651.09611595])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id      SalePrice\n",
      "0  1461  125901.076242\n",
      "1  1462  166688.911191\n",
      "2  1463  187303.574282\n",
      "3  1464  196341.358726\n",
      "4  1465  187206.275733\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'Id': data_test.Id, 'SalePrice': predictions})\n",
    "print(submission.head())\n",
    "submission.to_csv('submission9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared log error: 0.04456827227348986\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean squared log error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_pipeline = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', CatBoostRegressor())\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_pipeline = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', XGBRegressor())\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ml_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import sqrt\n",
    "# y_pred = ml_pipeline.predict(X_valid)\n",
    "\n",
    "# # Вычисление средней квадратичной ошибки\n",
    "# mse = mean_squared_error(y_valid, y_pred)\n",
    "# print('Mean Squared Error:', mse)\n",
    "\n",
    "# # Вычисление коэффициента детерминации (R^2)\n",
    "# r2 = r2_score(y_valid, y_pred)\n",
    "# print('R^2 Score:', r2)\n",
    "\n",
    "# rmse = sqrt(mse)\n",
    "# print('Root Mean Squared Error:', rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# err = np.sqrt(mean_squared_log_error(y_valid, y_pred))\n",
    "# err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ml_pipeline.fit(X, y)\n",
    "# predictions = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'Id': data_test.Id, 'SalePrice': predictions})\n",
    "# print(submission.head())\n",
    "# submission.to_csv('submission8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgi import test\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from altair import Column\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder,TargetEncoder\n",
    "from scipy.stats import ttest_ind\n",
    "import shap\n",
    "import catboost as cat\n",
    "\n",
    "from sklearn import pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor, make_column_selector\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.feature_selection import f_regression, chi2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# init js\n",
    "shap.initjs()\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Устанавливаем вывод pandas в удобочитаемый формат\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Настройка вывода pandas через sklearn\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Игнорируем предупреждения\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('test.csv')\n",
    "\n",
    "x_train_X=train.drop(['SalePrice'],axis=1)\n",
    "y_train_y=np.log1p (train['SalePrice'])\n",
    "\n",
    "\n",
    "\n",
    "class mypreprocess(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.nanistype=[\n",
    "            'Alley',\n",
    "            'BsmtQual',\n",
    "            'BsmtCond',\n",
    "            'BsmtExposure',\n",
    "            'BsmtFinType1',\n",
    "            'BsmtFinType2',\n",
    "            'FireplaceQu',\n",
    "            'GarageType',\n",
    "            'GarageFinish',\n",
    "            'GarageQual',\n",
    "            'GarageCond',\n",
    "            'PoolQC',\n",
    "            'Fence',\n",
    "            'MiscFeature',\n",
    "            'MasVnrType'\n",
    "        ]\n",
    "        self.rendict={\n",
    "            'name':'MSSubClass',\n",
    "            20: '1-STORY 1946 & NEWER ALL STYLES',\n",
    "            30: '1-STORY 1945 & OLDER',\n",
    "            40: '1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "            45: '1-1/2 STORY - UNFINISHED ALL AGES',\n",
    "            50: '1-1/2 STORY FINISHED ALL AGES',\n",
    "            60: '2-STORY 1946 & NEWER',\n",
    "            70: '2-STORY 1945 & OLDER',\n",
    "            75: '2-1/2 STORY ALL AGES',\n",
    "            80: 'SPLIT OR MULTI-LEVEL',\n",
    "            85: 'SPLIT FOYER',\n",
    "            90: 'DUPLEX - ALL STYLES AND AGES',\n",
    "            120: '1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
    "            150: '1-1/2 STORY PUD - ALL AGES',\n",
    "            160: '2-STORY PUD - 1946 & NEWER',\n",
    "            180: 'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
    "            190: '2 FAMILY CONVERSION - ALL STYLES AND AGES'\n",
    "        }\n",
    "\n",
    "    def preprocess( self, df):\n",
    "       \n",
    "        df[self.rendict['name']]=df[self.rendict['name']].map( self.rendict)    \n",
    "        df[ self.nanistype]=df[self.nanistype].fillna('Empty')\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.preprocess(X)\n",
    "\n",
    "def show_nan_count(train):\n",
    "    d=pd.DataFrame(data={'NaN_count': train.isna().sum(), 'data_type': train.dtypes}).T\n",
    "    filtered_columns = d.columns[d.loc['NaN_count'] > 0]\n",
    "    filtered_df = d[filtered_columns]\n",
    "    return filtered_df\n",
    "\n",
    "#drop_features = ['Id','Alley','MasVnrType','FireplaceQu','PoolQC','Fence','MiscFeature','LandSlope','GarageQual','GarageCond','MiscVal','Utilities','YrSold', 'MSSubClass','OverallCond', 'LowQualFinSF', 'MiscVal', 'BsmtHalfBath', '3SsnPorch', 'MoSold', 'PoolArea']\n",
    "drop_features=['Id']\n",
    "firimputer= ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mypreprocess', mypreprocess(), x_train_X.columns)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "my_imputer = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('drop_features', 'drop', drop_features),\n",
    "        ('num_imputer', KNNImputer(n_neighbors=5), make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent'), make_column_selector(dtype_include='object'))\n",
    "    ],\n",
    "    verbose_feature_names_out = False,\n",
    "    remainder = 'passthrough'\n",
    ") \n",
    "scaler_and_encoder = ColumnTransformer(\n",
    "    [\n",
    "        ('target_encoding', TargetEncoder(), make_column_selector(dtype_include='object')),\n",
    "        ('scaling_num_columns', StandardScaler(), make_column_selector(dtype_include=['float64', 'int64']))\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        ('firimputer', firimputer),\n",
    "        ('imputer', my_imputer),\n",
    "        ('scaler_and_encoder', scaler_and_encoder),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = preprocessor.fit_transform(x_train_X,y_train_y)\n",
    "train_y = y_train_y\n",
    "\n",
    "\n",
    "randomseed = 42\n",
    "def rmse(y_true, y_pred):\n",
    "    return -np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# Создание кастомной метрики для использования в cross_val_score\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "def objectiveknn(trial):\n",
    "    params = {'n_neighbors': trial.suggest_int('n_neighbors', 1, 10)}\n",
    "    model = KNeighborsRegressor(**params)\n",
    "    scores =  cross_val_score(model, train_X, train_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "studyknn = optuna.create_study(direction='minimize')\n",
    "def objectivelasso(trial):\n",
    "    params = {'alpha': trial.suggest_float('alpha', 0.0, 1.0)}\n",
    "    model = Lasso(**params)\n",
    "    scores =  cross_val_score(model, train_X, train_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "studylasso = optuna.create_study(direction='minimize')\n",
    "def objectiveRidge(trial):\n",
    "    params = {'alpha': trial.suggest_float('alpha', 0.0, 1.0)}\n",
    "    model = Ridge(**params)\n",
    "    scores =  cross_val_score(model, train_X, train_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "studyRidge = optuna.create_study(direction='minimize')\n",
    "def ojectiveRandomForest(trial):\n",
    "    params = {'n_estimators': trial.suggest_int('n_estimators', 3, 10),\n",
    "              'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "              'min_samples_split': trial.suggest_int('min_samples_split', 2, 7)}\n",
    "    model = RandomForestRegressor(**params)\n",
    "    scores =  cross_val_score(model, train_X, train_y, cv=5, scoring=rmse_scorer)\n",
    "    return np.mean(scores)\n",
    "studyRandomForest = optuna.create_study(direction='minimize')\n",
    "\n",
    "\n",
    "studylasso.optimize(objectivelasso, n_trials=100)\n",
    "studyknn.optimize(objectiveknn, n_trials=100)\n",
    "studyRidge.optimize(objectiveRidge, n_trials=100)\n",
    "studyRandomForest.optimize(ojectiveRandomForest, n_trials=10)\n",
    "\n",
    "def gettt(model):\n",
    "    return TransformedTargetRegressor(regressor=model, func=np.expm1, inverse_func=np.log1p)\n",
    "cb =gettt(cat.CatBoostRegressor(random_seed=randomseed,iterations=300))\n",
    "rf = gettt(RandomForestRegressor(n_estimators=112, max_depth=12, min_samples_split=6))\n",
    "las=gettt(Lasso(**studylasso.best_params))\n",
    "ridge=gettt(Ridge())\n",
    "knn = gettt(KNeighborsRegressor( **studyknn.best_params))\n",
    "\n",
    "train_X,test_X,train_y,test_y = train_test_split(train_X, train_y, test_size=0.3,random_state=42)\n",
    "\n",
    "predcb=cb.fit(train_X,train_y).predict(test_X)\n",
    "predrf=rf.fit(train_X,train_y).predict(test_X)\n",
    "predlas=las.fit(train_X,train_y).predict(test_X)\n",
    "predridge=ridge.fit(train_X,train_y).predict(test_X)\n",
    "predknn=knn.fit(train_X,train_y).predict(test_X)\n",
    "\n",
    "def ojectiveweights(trial):\n",
    "    cbweight = trial.suggest_float('cbweight', 0.0, 1.0)\n",
    "    rfweight = trial.suggest_float('rfweight', 0.0, 1.0)\n",
    "    lasweight = trial.suggest_float('lasweight', 0.0, 1.0)\n",
    "    ridgeweight = trial.suggest_float('ridgeweight', 0.0, 1.0)\n",
    "    knnweight = trial.suggest_float('knnweight', 0.0, 1.0)\n",
    "    pred= (cbweight*predcb+rfweight*predrf+lasweight*predlas+ridgeweight*predridge+knnweight*predknn)/(cbweight+rfweight+lasweight+ridgeweight+knnweight)\n",
    "    return rmse(test_y, pred)\n",
    "\n",
    "studyweights = optuna.create_study(direction='minimize')\n",
    "studyweights.optimize(ojectiveweights, n_trials=100)\n",
    "weights=[studyweights.best_params['cbweight'],studyweights.best_params['rfweight'],studyweights.best_params['lasweight'],studyweights.best_params['ridgeweight'],studyweights.best_params['knnweight']]\n",
    "v = VotingRegressor(estimators=[('cb', cb), ('rf', rf), ('las', las), ('ridge', ridge), ('knn', knn)], weights=weights)\n",
    "# Создание и обучение модели с логарифмическим преобразованием целевой переменной\n",
    "ml_pipeline_log = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model_log', v)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ml_pipeline_log.fit(train_X,train_y)\n",
    "\n",
    "pred = ml_pipeline_log.predict(test_X) \n",
    "RMSLE(test_y, pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пробуем модель randomforest результат 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_pipeline = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', RandomForestRegressor(n_estimators=112, max_depth=12, min_samples_split=6))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20)\n",
    "#     }\n",
    "\n",
    "#     model = RandomForestRegressor(**params)\n",
    "\n",
    "#     # Создаем Pipeline с предобработкой и моделью\n",
    "#     pipeline = Pipeline([\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "\n",
    "#     # Оцениваем модель с помощью кросс-валидации\n",
    "#     scores = -cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "# print('Лучшие гиперпараметры:', study.best_params)\n",
    "# print('Минимальное значение MSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пробуем модель xgboost 0.15764922452888183\n",
    "#n_estimators=129, max_depth=6, learning_rate=0.04291606041049112, subsample=0.6739178958863075, colsample_bytree=0.7508549367177377, gamma=0.5050428979601813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пробуем модель CatBoostRegressor 0.10821851593205858\n",
    "#пока что лучшие показатели, попробуем прогнать через оптюну\n",
    "#Лучшие гиперпараметры: {'n_estimators': 179, 'max_depth': 7, 'learning_rate': 0.06210223900648785, 'subsample': 0.7224302068857389, 'colsample_bylevel': 0.8319331845603969, 'reg_lambda': 0.9923582305360312}\n",
    "#Минимальное значение MSE: 5653456242.055735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_pipeline = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', CatBoostRegressor())\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
    "#     }\n",
    "\n",
    "#     model = CatBoostRegressor(**params, verbose=0)\n",
    "\n",
    "#     # Создаем Pipeline с предобработкой и моделью\n",
    "#     pipeline = Pipeline([\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "\n",
    "#     # Оцениваем модель с помощью кросс-валидации\n",
    "#     scores = -cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "# print('Лучшие гиперпараметры:', study.best_params)\n",
    "# print('Минимальное значение MSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'gamma': trial.suggest_float('gamma', 0.0, 1.0)\n",
    "#     }\n",
    "\n",
    "#     model = XGBRegressor(**params)\n",
    "\n",
    "#     # Создаем Pipeline с предобработкой и моделью\n",
    "#     pipeline = Pipeline([\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "\n",
    "#     # Оцениваем модель с помощью кросс-валидации\n",
    "#     scores = -cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "# print('Лучшие гиперпараметры:', study.best_params)\n",
    "# print('Минимальное значение MSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# y_train_log = np.log1p(y_train)\n",
    "# y_valid_log = np.log1p(y_valid)\n",
    "\n",
    "# # Создание модели с логарифмическим преобразованием целевой переменной\n",
    "# ml_pipeline_log = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model_log', TransformedTargetRegressor(regressor=CatBoostRegressor(), func=np.expm1, inverse_func=np.log1p))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Обучение модели\n",
    "# ml_pipeline_log.fit(X_train, y_train_log)\n",
    "\n",
    "# # Предсказания на валидационном наборе данных\n",
    "# y_pred_log = ml_pipeline_log.predict(X_valid)\n",
    "\n",
    "# # Оценка модели по mean_squared_log_error\n",
    "# err = np.sqrt(mean_squared_log_error(y_valid_log, y_pred_log))\n",
    "# print(\"RMSE на логарифмированной целевой переменной: \", err)\n",
    "\n",
    "\n",
    "# # y_log = np.log1p(y)\n",
    "\n",
    "# # # Создание и обучение модели с логарифмическим преобразованием целевой переменной\n",
    "# # ml_pipeline_log = Pipeline(\n",
    "# #     [\n",
    "# #         ('preprocessor', preprocessor),\n",
    "# #         ('model_log', TransformedTargetRegressor(regressor=CatBoostRegressor(), func=np.expm1, inverse_func=np.log1p))\n",
    "# #     ]\n",
    "# # )\n",
    "\n",
    "# model = ml_pipeline_log.fit(X, y)\n",
    "\n",
    "# # Предсказания на тестовом наборе данных\n",
    "# predictions = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# y_train_log = np.log1p(y_train)\n",
    "# y_valid_log = np.log1p(y_valid)\n",
    "\n",
    "# ml_pipeline_log = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model_log', TransformedTargetRegressor(regressor=CatBoostRegressor(), func=np.expm1, inverse_func=np.log1p))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ml_pipeline_log.fit(X_train, y_train_log)\n",
    "\n",
    "# # Скопировать обработку данных из ml_pipeline_log\n",
    "# preprocessor = ml_pipeline_log.named_steps['preprocessor']\n",
    "\n",
    "# # Создание и обучение модели без логарифмического преобразования целевой переменной\n",
    "# ml_pipeline = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', CatBoostRegressor())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Обучение модели без логарифмического преобразования целевой переменной\n",
    "# model = ml_pipeline.fit(X, y)\n",
    "\n",
    "# # Предсказания на тестовом наборе данных\n",
    "# predictions = model.predict(data_test)\n",
    "\n",
    "# # Оценка модели по mean_squared_log_error\n",
    "# y_pred_log = ml_pipeline_log.predict(X_valid)\n",
    "# err = np.sqrt(mean_squared_log_error(np.expm1(y_valid_log), np.expm1(y_pred_log)))\n",
    "# print(f\"Mean squared log error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'Id': data_test.Id, 'SalePrice': predictions})\n",
    "# print(submission.head())\n",
    "# submission.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# y_log = np.log1p(y)\n",
    "\n",
    "# # Создание и обучение модели с логарифмическим преобразованием целевой переменной\n",
    "# ml_pipeline_log = Pipeline(\n",
    "#     [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model_log', TransformedTargetRegressor(regressor=CatBoostRegressor(), func=np.expm1, inverse_func=np.log1p))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model = ml_pipeline_log.fit(X, y_log)\n",
    "# y_pred_l = ml_pipeline_log.predict(X_valid)\n",
    "# y_pred = np.expm1(y_pred_l)\n",
    "\n",
    "# err = np.sqrt(mean_squared_log_error(y_valid, y_pred))\n",
    "# print(f\"Mean squared log error: {err}\")\n",
    "\n",
    "# model = ml_pipeline_log.fit(X, y_log)\n",
    "# predictions_log = model.predict(data_test)\n",
    "# predictions = np.expm1(predictions_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'Id': data_test.Id, 'SalePrice': predictions})\n",
    "# print(submission.head())\n",
    "# submission.to_csv('submission9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'Id': data_test.Id, 'SalePrice': predictions})\n",
    "# print(submission.head())\n",
    "# submission.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# msle = mean_squared_log_error(np.expm1(y_log), np.expm1(predictions))\n",
    "# print(\"Mean Squared Log Error:\", msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import sqrt\n",
    "# y_pred = ml_pipeline.predict(X_valid)\n",
    "\n",
    "# # Вычисление средней квадратичной ошибки\n",
    "# mse = mean_squared_error(y_valid, y_pred)\n",
    "# print('Mean Squared Error:', mse)\n",
    "\n",
    "# # Вычисление коэффициента детерминации (R^2)\n",
    "# r2 = r2_score(y_valid, y_pred)\n",
    "# print('R^2 Score:', r2)\n",
    "\n",
    "# rmse = sqrt(mse)\n",
    "# print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "#Mean Squared Error: 1505777279.764108\n",
    "# R^2 Score: 0.7450421931135391\n",
    "# Root Mean Squared Error: 38804.346145298055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# err = np.sqrt(mean_squared_log_error(y_valid, y_pred))\n",
    "# err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ml_pipeline.fit(X, y)\n",
    "# predictions = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'Id': data_test.Id, 'SalePrice': predictions})\n",
    "# print(submission.head())\n",
    "# submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "#     }\n",
    "\n",
    "#     rf = RandomForestRegressor(**params)\n",
    "#     scores = -1 * cross_val_score(rf, X, y, cv=KFold(n_splits=5, shuffle=True), scoring='neg_mean_squared_error')\n",
    "\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # Получаем лучшие параметры модели\n",
    "# best_params = study.best_params\n",
    "# best_score = study.best_value\n",
    "\n",
    "# print(\"Лучшие параметры модели, полученные с кросс-валидацией:\")\n",
    "# print(best_params)\n",
    "# print(\"Средний score с кросс-валидацией:\")\n",
    "# print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20)\n",
    "#     }\n",
    "\n",
    "#     model = RandomForestRegressor(**params)\n",
    "#     ml_pipeline = Pipeline(\n",
    "#     [\n",
    "#             ('preprocessor', preprocessor),\n",
    "#             ('model', model)\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "#     # Оцениваем модель с помощью кросс-валидации\n",
    "#     scores = -cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# # Создаем и запускаем Optuna Study\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=50)\n",
    "\n",
    "# # Получаем лучшие гиперпараметры\n",
    "# best_params = study.best_params\n",
    "# print(\"Лучшие гиперпараметры:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
